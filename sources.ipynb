{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL - Extract, Transform, Load\n",
    "# Get data from multiple sources (Databases, files, API, etc.)\n",
    "# Transform the data to be useable - (weather e.x.: T for rain - (trace), near nothing).\n",
    "# Load data - store / save our data, often to a database or a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from requests import get, HTTPError, ConnectionError\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_endpoint = 'https://www.reddit.com/r/machinelearning/.json'\n",
    "json_data = None\n",
    "try:\n",
    "    req = get(reddit_endpoint, headers = {\"User-agent\": \"max-etl-pipeline\"})\n",
    "    json_data = req.json()\n",
    "except (HTTPError, ConnectionError) as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kind': 'Listing', 'data': {'after': 't3_18r6wqx', 'dist': 26, 'modhash': '', 'geo_filter': None, 'children': [{'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\\n\\nThread will stay alive until next one so keep posting after the date in the title.\\n\\nThanks to everyone for answering questions in the previous thread!', 'author_fullname': 't2_6l4z3', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] Simple Questions Thread', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18kkdbb', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': True, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1702828819.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!&lt;/p&gt;\\n\\n&lt;p&gt;Thread will stay alive until next one so keep posting after the date in the title.&lt;/p&gt;\\n\\n&lt;p&gt;Thanks to everyone for answering questions in the previous thread!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': 'new', 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18kkdbb', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'AutoModerator', 'discussion_type': None, 'num_comments': 59, 'send_replies': False, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/', 'parent_whitelist_status': 'all_ads', 'stickied': True, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/', 'subreddit_subscribers': 2846730, 'created_utc': 1702828819.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'So I see that Mixtral 8x7b has only 45B parameters as opposed to 56B (src https://huggingface.co/blog/mixtral) because MoE apply to feedforward layers only and not attention layers. Why is it the case? I believe there is certainly research on applying MoE to attention layers, but why is it not used? Is it not improving performance or something, and is there any tasks where MoE on attention layers help?', 'author_fullname': 't2_1czuggqh', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] Why MoE models target only feedforward layers?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18rzygz', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.89, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 13, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 13, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703681296.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I see that Mixtral 8x7b has only 45B parameters as opposed to 56B (src &lt;a href=\"https://huggingface.co/blog/mixtral\"&gt;https://huggingface.co/blog/mixtral&lt;/a&gt;) because MoE apply to feedforward layers only and not attention layers. Why is it the case? I believe there is certainly research on applying MoE to attention layers, but why is it not used? Is it not improving performance or something, and is there any tasks where MoE on attention layers help?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/fYhTfAO7tHC_0sTrPP_SqCyMQAfBgcaAT4wNE84Hwkw.jpg?auto=webp&amp;s=18392421f50d76904755e1743050631aa897626b', 'width': 2400, 'height': 1360}, 'resolutions': [{'url': 'https://external-preview.redd.it/fYhTfAO7tHC_0sTrPP_SqCyMQAfBgcaAT4wNE84Hwkw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=412b985bb48f646d777c0d5a7338b25941f87d22', 'width': 108, 'height': 61}, {'url': 'https://external-preview.redd.it/fYhTfAO7tHC_0sTrPP_SqCyMQAfBgcaAT4wNE84Hwkw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d7703134af30a4969ce49a5b4d63a8615e647429', 'width': 216, 'height': 122}, {'url': 'https://external-preview.redd.it/fYhTfAO7tHC_0sTrPP_SqCyMQAfBgcaAT4wNE84Hwkw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=45c8c531c29d14ca56aa1d1568f8a1758547b9ff', 'width': 320, 'height': 181}, {'url': 'https://external-preview.redd.it/fYhTfAO7tHC_0sTrPP_SqCyMQAfBgcaAT4wNE84Hwkw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f5543333ebdc8bba00f6c96176dc1e3c0788e462', 'width': 640, 'height': 362}, {'url': 'https://external-preview.redd.it/fYhTfAO7tHC_0sTrPP_SqCyMQAfBgcaAT4wNE84Hwkw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e9e301c44a1e938ac502590fe2fa01197a140b84', 'width': 960, 'height': 544}, {'url': 'https://external-preview.redd.it/fYhTfAO7tHC_0sTrPP_SqCyMQAfBgcaAT4wNE84Hwkw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fc537eab3fe347e1caadce52dd7e327ae4981f39', 'width': 1080, 'height': 612}], 'variants': {}, 'id': 'SJQlWEJm59asnHgX8hrcfMHMeUUmC7t3h9Z20fpFVtY'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18rzygz', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'vincent163', 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18rzygz/d_why_moe_models_target_only_feedforward_layers/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18rzygz/d_why_moe_models_target_only_feedforward_layers/', 'subreddit_subscribers': 2846730, 'created_utc': 1703681296.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Learning ML, I’ve always been interested in **PyTorch** and its **Autograd engine**. \\n\\nIn [this project](https://github.com/eduardoleao052/Autograd-from-scratch.git), I tried to **reimplement most of PyTorch** (including the Autograd) from scratch in a **well-documented, unit tested, and interpretable** way. It was really useful for me, and I hope it can help you understand Autograd better as well! \\n\\nHope you enjoy! \\n\\nGitHub repository [here](https://github.com/eduardoleao052/Autograd-from-scratch.git)!', 'author_fullname': 't2_jxw66snkb', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[P] I made an Educational Autograd from scratch', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18s0adx', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.84, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 8, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 8, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703682389.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Learning ML, I’ve always been interested in &lt;strong&gt;PyTorch&lt;/strong&gt; and its &lt;strong&gt;Autograd engine&lt;/strong&gt;. &lt;/p&gt;\\n\\n&lt;p&gt;In &lt;a href=\"https://github.com/eduardoleao052/Autograd-from-scratch.git\"&gt;this project&lt;/a&gt;, I tried to &lt;strong&gt;reimplement most of PyTorch&lt;/strong&gt; (including the Autograd) from scratch in a &lt;strong&gt;well-documented, unit tested, and interpretable&lt;/strong&gt; way. It was really useful for me, and I hope it can help you understand Autograd better as well! &lt;/p&gt;\\n\\n&lt;p&gt;Hope you enjoy! &lt;/p&gt;\\n\\n&lt;p&gt;GitHub repository &lt;a href=\"https://github.com/eduardoleao052/Autograd-from-scratch.git\"&gt;here&lt;/a&gt;!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/IFc8Ke97hZgCQXosSoHemeZ2nALg2728l99EodureBc.jpg?auto=webp&amp;s=85b9b93833e6d89fd6e6b6d0e104bb3c536a1b89', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/IFc8Ke97hZgCQXosSoHemeZ2nALg2728l99EodureBc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=02531a946956b0a2855b8b5e2ab1a4d08c64a3df', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/IFc8Ke97hZgCQXosSoHemeZ2nALg2728l99EodureBc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1922031a60d1af0642aa8804643bf9f453fc7648', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/IFc8Ke97hZgCQXosSoHemeZ2nALg2728l99EodureBc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad2fdd826af01afddf9e203fc02c60b6e1fc83b5', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/IFc8Ke97hZgCQXosSoHemeZ2nALg2728l99EodureBc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f85f8ce11a3250e43bfe63c461e4f6444499c14d', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/IFc8Ke97hZgCQXosSoHemeZ2nALg2728l99EodureBc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cdd02b9650c96f325e1ebc6521bfb277b91f5b2a', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/IFc8Ke97hZgCQXosSoHemeZ2nALg2728l99EodureBc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b86d2f66a4420fd01baea318f5a6d1a3b0f6b9cd', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'ZW0y7htALKaJ_L0rgKnS16d1SiKT2WRlASDRpwYO1F8'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18s0adx', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'suspicious_beam', 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18s0adx/p_i_made_an_educational_autograd_from_scratch/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18s0adx/p_i_made_an_educational_autograd_from_scratch/', 'subreddit_subscribers': 2846730, 'created_utc': 1703682389.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"Hi, I need to identify the roulette ball consistently with any roulette wheel (considering various colors and lighting environment).\\n\\nI figured I'd use opencv to add annotations to each recording, but I would have to define the initial box manually at the start of each video, which would take way too long. I am also very new to this, any suggestions? Any other way I could train the model?\", 'author_fullname': 't2_dhk7vseo1', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[P] Creating training data for tensorflow from footage', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_18s0wo2', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703684335.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I need to identify the roulette ball consistently with any roulette wheel (considering various colors and lighting environment).&lt;/p&gt;\\n\\n&lt;p&gt;I figured I&amp;#39;d use opencv to add annotations to each recording, but I would have to define the initial box manually at the start of each video, which would take way too long. I am also very new to this, any suggestions? Any other way I could train the model?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18s0wo2', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'No_Rough_1116', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18s0wo2/p_creating_training_data_for_tensorflow_from/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18s0wo2/p_creating_training_data_for_tensorflow_from/', 'subreddit_subscribers': 2846730, 'created_utc': 1703684335.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Hey guys, \\n\\nWe know that there are lots of deep learning tools like  Ultralytics and Roboflow that have created models that we can utilize easily, so can we use these models in Research papers?\\n\\nWe know that there are lots of deep learning tools like  Ultralytics and Roboflow that have created models that we can utilize them easily, so can we use these models in Research papers?\\n\\nAnd in the industry and companies, will the employer pay us for using these ready models or we have to create models with tensorflow and Pytorch from scratch?\\\\[D\\\\]', 'author_fullname': 't2_iiwgex0rl', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[Discussion]Which Deep Learning techniques are used in Research/industry?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_18s2vjn', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703689959.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, &lt;/p&gt;\\n\\n&lt;p&gt;We know that there are lots of deep learning tools like  Ultralytics and Roboflow that have created models that we can utilize easily, so can we use these models in Research papers?&lt;/p&gt;\\n\\n&lt;p&gt;We know that there are lots of deep learning tools like  Ultralytics and Roboflow that have created models that we can utilize them easily, so can we use these models in Research papers?&lt;/p&gt;\\n\\n&lt;p&gt;And in the industry and companies, will the employer pay us for using these ready models or we have to create models with tensorflow and Pytorch from scratch?[D]&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18s2vjn', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'pex4204', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18s2vjn/discussionwhich_deep_learning_techniques_are_used/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18s2vjn/discussionwhich_deep_learning_techniques_are_used/', 'subreddit_subscribers': 2846730, 'created_utc': 1703689959.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Resources that cover relevant things like ZeRO, Multi-GPU training, parallelism regimes, teaches CUDA / triton / openMP, and so on.', 'author_fullname': 't2_2624sc3z', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] Want recommendations for learning ML-oriented distributed systems', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18rnnuv', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.89, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 22, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 22, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703639140.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Resources that cover relevant things like ZeRO, Multi-GPU training, parallelism regimes, teaches CUDA / triton / openMP, and so on.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18rnnuv', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'PunsbyMann', 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18rnnuv/d_want_recommendations_for_learning_mloriented/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18rnnuv/d_want_recommendations_for_learning_mloriented/', 'subreddit_subscribers': 2846730, 'created_utc': 1703639140.0, 'num_crossposts': 1, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Link to CCS paper: [https://dl.acm.org/doi/10.1145/3576915.3623114](https://dl.acm.org/doi/10.1145/3576915.3623114)\\n\\nLink to pre-print: [https://arxiv.org/abs/2305.05355](https://arxiv.org/abs/2305.05355)\\n\\nLink GitHub: [https://github.com/DCALab-UNIPV/Turning-Privacy-preserving-Mechanisms-against-Federated-Learning](https://github.com/DCALab-UNIPV/Turning-Privacy-preserving-Mechanisms-against-Federated-Learning)\\n\\nAbstract:\\n\\nRecently, researchers have successfully employed Graph Neural  Networks (GNNs) to build enhanced recommender systems due to their  capability to learn patterns from the interaction between involved  entities. In addition, previous studies have investigated federated  learning as the main solution to enable a native privacy-preserving  mechanism for the construction of global GNN models without collecting  sensitive data into a single computation unit. Still, privacy issues may  arise as the analysis of local model updates produced by the federated  clients can return information related to sensitive local data. For this  reason, researchers proposed solutions that combine federated learning  with Differential Privacy strategies and community-driven approaches,  which involve combining data from neighbor clients to make the  individual local updates less dependent on local sensitive data.\\n\\nIn  this paper, we identify a crucial security flaw in such a configuration  and design an attack capable of deceiving state-of-the-art defenses for  federated learning. The proposed attack includes two operating modes,  the first one focusing on convergence inhibition (Adversarial Mode), and  the second one aiming at building a deceptive rating injection on the  global federated model (Backdoor Mode). The experimental results show  the effectiveness of our attack in both its modes, returning on average  60% performance detriment in all the tests on Adversarial Mode and fully  effective backdoors in 93% of cases for the tests performed on Backdoor  Mode.', 'author_fullname': 't2_ayul12d1', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[R] \"Turning Privacy-preserving Mechanisms against Federated Learning\" (CCS23) (Machine Learning Security)', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18rz528', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703678414.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Link to CCS paper: &lt;a href=\"https://dl.acm.org/doi/10.1145/3576915.3623114\"&gt;https://dl.acm.org/doi/10.1145/3576915.3623114&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Link to pre-print: &lt;a href=\"https://arxiv.org/abs/2305.05355\"&gt;https://arxiv.org/abs/2305.05355&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Link GitHub: &lt;a href=\"https://github.com/DCALab-UNIPV/Turning-Privacy-preserving-Mechanisms-against-Federated-Learning\"&gt;https://github.com/DCALab-UNIPV/Turning-Privacy-preserving-Mechanisms-against-Federated-Learning&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Abstract:&lt;/p&gt;\\n\\n&lt;p&gt;Recently, researchers have successfully employed Graph Neural  Networks (GNNs) to build enhanced recommender systems due to their  capability to learn patterns from the interaction between involved  entities. In addition, previous studies have investigated federated  learning as the main solution to enable a native privacy-preserving  mechanism for the construction of global GNN models without collecting  sensitive data into a single computation unit. Still, privacy issues may  arise as the analysis of local model updates produced by the federated  clients can return information related to sensitive local data. For this  reason, researchers proposed solutions that combine federated learning  with Differential Privacy strategies and community-driven approaches,  which involve combining data from neighbor clients to make the  individual local updates less dependent on local sensitive data.&lt;/p&gt;\\n\\n&lt;p&gt;In  this paper, we identify a crucial security flaw in such a configuration  and design an attack capable of deceiving state-of-the-art defenses for  federated learning. The proposed attack includes two operating modes,  the first one focusing on convergence inhibition (Adversarial Mode), and  the second one aiming at building a deceptive rating injection on the  global federated model (Backdoor Mode). The experimental results show  the effectiveness of our attack in both its modes, returning on average  60% performance detriment in all the tests on Adversarial Mode and fully  effective backdoors in 93% of cases for the tests performed on Backdoor  Mode.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/y4CEtN0xjw2skH93bdUbzTjjEQ2Hhssqe97OiB5o3x8.jpg?auto=webp&amp;s=9ef5604205569083d63994f33666eb623964a785', 'width': 302, 'height': 392}, 'resolutions': [{'url': 'https://external-preview.redd.it/y4CEtN0xjw2skH93bdUbzTjjEQ2Hhssqe97OiB5o3x8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8d213cec0fce006d5addf3fd5f93553c806c2272', 'width': 108, 'height': 140}, {'url': 'https://external-preview.redd.it/y4CEtN0xjw2skH93bdUbzTjjEQ2Hhssqe97OiB5o3x8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6befb291749df8f7200f2dbc98aa3dbc16ceb631', 'width': 216, 'height': 280}], 'variants': {}, 'id': 'ZH9NGfzHyf0LmT4bg_xOgO6UjIBLGgRiHbGlgFIVcNE'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18rz528', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'ArmandolandoReal', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18rz528/r_turning_privacypreserving_mechanisms_against/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18rz528/r_turning_privacypreserving_mechanisms_against/', 'subreddit_subscribers': 2846730, 'created_utc': 1703678414.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"Per title, I'm wondering if there are specific implementations of Transformers that people typically use? I don't care for pre-trained models. I want a minimal / clean implementation that I can use to modify the Transformer architecture itself for some ideas I have. I noticed that PyTorch has it its own built-in Transformers, but not sure if they're any good and they looked like they might be a bit over-engineered for my needs. I also noticed Andrej Karpathy has his nanoGPT project which might fit the bill (a decoder-only autoregressive implementation is fine for what I want.)\", 'author_fullname': 't2_1tf9', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] Which Transformer implementation do people typically use?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18r8yhf', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.95, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 104, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 104, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703599969.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Per title, I&amp;#39;m wondering if there are specific implementations of Transformers that people typically use? I don&amp;#39;t care for pre-trained models. I want a minimal / clean implementation that I can use to modify the Transformer architecture itself for some ideas I have. I noticed that PyTorch has it its own built-in Transformers, but not sure if they&amp;#39;re any good and they looked like they might be a bit over-engineered for my needs. I also noticed Andrej Karpathy has his nanoGPT project which might fit the bill (a decoder-only autoregressive implementation is fine for what I want.)&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18r8yhf', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'SuperFX', 'discussion_type': None, 'num_comments': 30, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18r8yhf/d_which_transformer_implementation_do_people/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18r8yhf/d_which_transformer_implementation_do_people/', 'subreddit_subscribers': 2846730, 'created_utc': 1703599969.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': '**\\\\[D\\\\] When we want to apply data reduction to a class-based dataset while preserving the data character, we try to maintain class ratios. What do we do when we want to apply data reduction while working with numerical data?**', 'author_fullname': 't2_60ibtfyy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] How to apply data reduction to numeric data while preserving the data character?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_18s33gl', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703690554.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;[D] When we want to apply data reduction to a class-based dataset while preserving the data character, we try to maintain class ratios. What do we do when we want to apply data reduction while working with numerical data?&lt;/strong&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18s33gl', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'SomeRestaurant8', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18s33gl/d_how_to_apply_data_reduction_to_numeric_data/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18s33gl/d_how_to_apply_data_reduction_to_numeric_data/', 'subreddit_subscribers': 2846730, 'created_utc': 1703690554.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': '\\nHello, I am a recent undergrad graduate and I am currently a research engineer at an ML startup (multimodal LLMs). I want to join a research lab at a university and work on a research project. I personally worked with the PI before and their lab is not super related to my startup research. \\n\\nI wanted to hear if anyone had similar experience of joining a lab while working in industry full time and anything I should be aware of. I would join without pay and use my own equipment for lab work. \\n\\nThis is because while I am doing meaningful research at the startup, I want to occupy myself more and become a more competent applicant for potential ML PhD. \\n\\nThanks!', 'author_fullname': 't2_5tz9lw5l', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] joining academia research lab while working full time as research engineer in industry.', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18rixog', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.85, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 24, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 24, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703626595.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am a recent undergrad graduate and I am currently a research engineer at an ML startup (multimodal LLMs). I want to join a research lab at a university and work on a research project. I personally worked with the PI before and their lab is not super related to my startup research. &lt;/p&gt;\\n\\n&lt;p&gt;I wanted to hear if anyone had similar experience of joining a lab while working in industry full time and anything I should be aware of. I would join without pay and use my own equipment for lab work. &lt;/p&gt;\\n\\n&lt;p&gt;This is because while I am doing meaningful research at the startup, I want to occupy myself more and become a more competent applicant for potential ML PhD. &lt;/p&gt;\\n\\n&lt;p&gt;Thanks!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18rixog', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Few_Ad1273', 'discussion_type': None, 'num_comments': 7, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18rixog/d_joining_academia_research_lab_while_working/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18rixog/d_joining_academia_research_lab_while_working/', 'subreddit_subscribers': 2846730, 'created_utc': 1703626595.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'I am specifically thinking of projects in the vein of [this](https://simdl.github.io/files/59.pdf) one.  The common situation is one in which the input data is planets, stars or similarly large enough bodies to have gravitational force.  And so using their masses and coordinates as the input to obtain the relation F=GM1M2/(r\\\\^2).  Do you know of any other type of projects where ML was used to identify such relations?\\n\\nAnd to what extent is ML capable of isolating and identifying such relations between input features of data?', 'author_fullname': 't2_1ehvpfw8', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[R] Does anyone know of ML projects that attempt to find specific relations between features?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18ry97g', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703674946.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am specifically thinking of projects in the vein of &lt;a href=\"https://simdl.github.io/files/59.pdf\"&gt;this&lt;/a&gt; one.  The common situation is one in which the input data is planets, stars or similarly large enough bodies to have gravitational force.  And so using their masses and coordinates as the input to obtain the relation F=GM1M2/(r^2).  Do you know of any other type of projects where ML was used to identify such relations?&lt;/p&gt;\\n\\n&lt;p&gt;And to what extent is ML capable of isolating and identifying such relations between input features of data?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18ry97g', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'emaxwell13131313', 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18ry97g/r_does_anyone_know_of_ml_projects_that_attempt_to/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18ry97g/r_does_anyone_know_of_ml_projects_that_attempt_to/', 'subreddit_subscribers': 2846730, 'created_utc': 1703674946.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Hello all, I have a dataset of medical questions split by categories, but the data is imbalanced, i have some categories that have 2000 record while some has 50 - 100, I used nlpaug to augment the data and used Wordcloud to visualize the top words, I found that most of the categories have  \"information technology\" and \"atomic number\" dominating.\\nAre there any augmentation libraries specific for medical text data ?\\n\\nThanks in advance', 'author_fullname': 't2_2zj2xaar', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] Are there any text augmentation libraries for medical text data?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_18s2aw1', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703688385.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I have a dataset of medical questions split by categories, but the data is imbalanced, i have some categories that have 2000 record while some has 50 - 100, I used nlpaug to augment the data and used Wordcloud to visualize the top words, I found that most of the categories have  &amp;quot;information technology&amp;quot; and &amp;quot;atomic number&amp;quot; dominating.\\nAre there any augmentation libraries specific for medical text data ?&lt;/p&gt;\\n\\n&lt;p&gt;Thanks in advance&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18s2aw1', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'skillmaker', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18s2aw1/d_are_there_any_text_augmentation_libraries_for/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18s2aw1/d_are_there_any_text_augmentation_libraries_for/', 'subreddit_subscribers': 2846730, 'created_utc': 1703688385.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"I mean, an assistant to whom I could talk and ask it to do anything in the computer.\\n\\nFor example: Open Netflix and play some movie, and also write an email to my mom with a recipe of something you find on the internet. Oh, and open the League of Legends and download it's updates.\\n\\nAll of it while making me some coffee and not touching a button.\\n\\nDoes that technology already exists?\", 'author_fullname': 't2_125l26', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] When are we going to have a full Windows/Linux/MacOS virtual assistant?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18s0e14', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.44, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703682717.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I mean, an assistant to whom I could talk and ask it to do anything in the computer.&lt;/p&gt;\\n\\n&lt;p&gt;For example: Open Netflix and play some movie, and also write an email to my mom with a recipe of something you find on the internet. Oh, and open the League of Legends and download it&amp;#39;s updates.&lt;/p&gt;\\n\\n&lt;p&gt;All of it while making me some coffee and not touching a button.&lt;/p&gt;\\n\\n&lt;p&gt;Does that technology already exists?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18s0e14', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'cosapocha', 'discussion_type': None, 'num_comments': 7, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18s0e14/d_when_are_we_going_to_have_a_full/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18s0e14/d_when_are_we_going_to_have_a_full/', 'subreddit_subscribers': 2846730, 'created_utc': 1703682717.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"I have some big models I want to run RL on and would prefer to avoid buying a zillion GPUs. Also it seems like this could be an interesting research area. Does anybody know if there are any papers or articles detailing using techniques like LoRA for RL?\\n\\nedit: Just for clarification, I'm referring to RL in general, not RLHF.\", 'author_fullname': 't2_6pkxsu2c', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': \"[D] Has there been any research into using parameter-efficient training like LoRA and QLoRA during RL for pretrained models? I haven't been able to find literature on this.\", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18s0dz2', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1703686714.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703682712.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some big models I want to run RL on and would prefer to avoid buying a zillion GPUs. Also it seems like this could be an interesting research area. Does anybody know if there are any papers or articles detailing using techniques like LoRA for RL?&lt;/p&gt;\\n\\n&lt;p&gt;edit: Just for clarification, I&amp;#39;m referring to RL in general, not RLHF.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18s0dz2', 'is_robot_indexable': True, 'report_reasons': None, 'author': '30299578815310', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18s0dz2/d_has_there_been_any_research_into_using/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18s0dz2/d_has_there_been_any_research_into_using/', 'subreddit_subscribers': 2846730, 'created_utc': 1703682712.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'I have a large database with different types of errors in temporal sequence. Example: A, C, F, C, G, D, A, G,...., F, G, D, A... F, S, G, D, H, A... \\nWhat algorithms can I use to find repeating patterns? (In the example: to discover that when F, G and D occur, A subsequently occurs).\\nThanksssss :)', 'author_fullname': 't2_jcsqmcrr', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] Algorithm to find patterns in temporal sequences', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18rft8z', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.82, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 18, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 18, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703618358.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a large database with different types of errors in temporal sequence. Example: A, C, F, C, G, D, A, G,...., F, G, D, A... F, S, G, D, H, A... \\nWhat algorithms can I use to find repeating patterns? (In the example: to discover that when F, G and D occur, A subsequently occurs).\\nThanksssss :)&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18rft8z', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'BusinessBaby9338', 'discussion_type': None, 'num_comments': 22, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18rft8z/d_algorithm_to_find_patterns_in_temporal_sequences/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18rft8z/d_algorithm_to_find_patterns_in_temporal_sequences/', 'subreddit_subscribers': 2846730, 'created_utc': 1703618358.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"So in my college I don't have much compute resources.What kind of work can I can do in ML?\", 'author_fullname': 't2_pqi16q1jf', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What kind of research can you do if you are GPU poor?[R]', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18r2nbu', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.93, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 144, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 144, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703575406.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So in my college I don&amp;#39;t have much compute resources.What kind of work can I can do in ML?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18r2nbu', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'One_Definition_8975', 'discussion_type': None, 'num_comments': 113, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18r2nbu/what_kind_of_research_can_you_do_if_you_are_gpu/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18r2nbu/what_kind_of_research_can_you_do_if_you_are_gpu/', 'subreddit_subscribers': 2846730, 'created_utc': 1703575406.0, 'num_crossposts': 1, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"**Background**: I'm currently doing research that involves automating this niche physics task with input from a camera. Basically given a certain shape/brightness of a pattern of light coming in, I can get these coordinates. Normally this is done with a large matrix inversion algorithm, but this takes a lot of time. Since the task is meant to be done in real-time, the idea is to make a neural network that can substitute for the inversion algorithm. I come from a physics background so while I know the basics of ML, all this image processing and more advanced neural network stuff is really new to me.\\n\\n**Issue**: Since each experiment is really expensive to run, I only have a thousand or so images to work off of which isn't nearly enough to get the high-level precision I need (probably R\\\\^2 &gt; .8 at least). On top of that, camera has been reoriented over the years due to different experimental needs and contraints by other groups. So I can't use a fully data-drive approach (I actually tried it though and got really good accuracy when using simple ML models for the few images I did have).\\n\\n**Approach**: The good news is that we do have a way to recreate a very rough shape of the pattern given the coordinates. So technically I could make a lot of synthetic images to train on. However, aside fromm the bascially 0th order similarity, it's a completely different image than irl. Like imagine you have a picture of the moon and you're trying to get the craters. Synthetic-image wise I have something that can outline a circle where each crater is.\\n\\nI tried doing line detection techniques which worked poorly. I also naively recreated all the synthetic images from the images I already had, then trained it on the synthetic and tested on the real, and got really bad results -- mostly because I'm just doing this really haphazardly at the moment. Most of the research I looked into synthetic images is for classification. So I'm wondering what else I could look into for getting accurate regression from synthetic images.\\n\\nSome things I've considered looking into were VAEs, feature extraction, more image processing techniques, and maybe GANs? One thing someone in my lab brought up was that I could try to use components of YOLO on the synthetic images, then I can fine tune the model on the real dataset I have. I would really appreciate any advice.\", 'author_fullname': 't2_h2qrf4dgq', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[P] Training an accurate regressive neural network on synthetic image data?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18rr0oz', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.71, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703649043.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: I&amp;#39;m currently doing research that involves automating this niche physics task with input from a camera. Basically given a certain shape/brightness of a pattern of light coming in, I can get these coordinates. Normally this is done with a large matrix inversion algorithm, but this takes a lot of time. Since the task is meant to be done in real-time, the idea is to make a neural network that can substitute for the inversion algorithm. I come from a physics background so while I know the basics of ML, all this image processing and more advanced neural network stuff is really new to me.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Issue&lt;/strong&gt;: Since each experiment is really expensive to run, I only have a thousand or so images to work off of which isn&amp;#39;t nearly enough to get the high-level precision I need (probably R^2 &amp;gt; .8 at least). On top of that, camera has been reoriented over the years due to different experimental needs and contraints by other groups. So I can&amp;#39;t use a fully data-drive approach (I actually tried it though and got really good accuracy when using simple ML models for the few images I did have).&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Approach&lt;/strong&gt;: The good news is that we do have a way to recreate a very rough shape of the pattern given the coordinates. So technically I could make a lot of synthetic images to train on. However, aside fromm the bascially 0th order similarity, it&amp;#39;s a completely different image than irl. Like imagine you have a picture of the moon and you&amp;#39;re trying to get the craters. Synthetic-image wise I have something that can outline a circle where each crater is.&lt;/p&gt;\\n\\n&lt;p&gt;I tried doing line detection techniques which worked poorly. I also naively recreated all the synthetic images from the images I already had, then trained it on the synthetic and tested on the real, and got really bad results -- mostly because I&amp;#39;m just doing this really haphazardly at the moment. Most of the research I looked into synthetic images is for classification. So I&amp;#39;m wondering what else I could look into for getting accurate regression from synthetic images.&lt;/p&gt;\\n\\n&lt;p&gt;Some things I&amp;#39;ve considered looking into were VAEs, feature extraction, more image processing techniques, and maybe GANs? One thing someone in my lab brought up was that I could try to use components of YOLO on the synthetic images, then I can fine tune the model on the real dataset I have. I would really appreciate any advice.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18rr0oz', 'is_robot_indexable': True, 'report_reasons': None, 'author': '30th-account', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18rr0oz/p_training_an_accurate_regressive_neural_network/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18rr0oz/p_training_an_accurate_regressive_neural_network/', 'subreddit_subscribers': 2846730, 'created_utc': 1703649043.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'My 3070 is increasingly holding me back for R&amp;D, and I\\'ve been on the cloud more and more not just for running jobs but for active research. I feel like I\\'m just burning money on the cloud and it\\'s just not sustainable. I need to invest some $$ and time into building a high quality (although smaller still) server to conduct my research.\\n\\nI\\'ve been struggling to find good detailed resources/communities for this. Most people seem to be content with the cloud, or their university/company handles this stuff for them. I anticipate that just googling to decide my setup, I\\'m gonna miss some crucial insider knowledge.\\n\\nI was hoping someone could offer some tips, or even better point me to a community thats extremely passionate about this side of AI dev? I live in Austin, if there\\'s any in person communities there, even better!\\n\\nIdeas I\\'ve been thinking for initial setup- probably just 2 or 3 4080s to start- I hear about NVLink, but don\\'t think that\\'s gonna be an option as someone who\\'s not well connected- a case (or rack?) and motherboard that can handle a few more (maybe 4-10 GPU capacity)- make sure that other specs (cooling, CPU, PSU, etc.) are appropriate and don\\'t bottleneck the GPUs- open case? closed case?? idk- would need to be able to ssh in from anywhere in austin, ideally anywhere in the US connection wouldn\\'t have too bad of latancy- my intention for the setup is to be what you should expect from an extremely new/lean/poor but ambitious and very smart/strategic startup, where people look back and say \"wow, that was a well researched and smart setup\" LOL\\n\\nAny advice, any connects, all appreciated. Thanks so much in advance! &lt;3 :-)  \\n\\n\\nEDIT: Thank you everyone soo so much! Seriously a lot of great resources here, very grateful! Will likely be following a server grade setup as u/nero10578 mentioned, and still have to dig deeper into a lot of the other resources mentioned as I get into the details of the setup.  \\n\\n\\np.s. sorry I posted and ghosted lol, have been hanging with family all week!', 'author_fullname': 't2_36soyahx', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[R], [P] Self-Hosted GPU setup for AI Research', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18rb7lo', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.77, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 16, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 16, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1703690621.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703606395.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My 3070 is increasingly holding me back for R&amp;amp;D, and I&amp;#39;ve been on the cloud more and more not just for running jobs but for active research. I feel like I&amp;#39;m just burning money on the cloud and it&amp;#39;s just not sustainable. I need to invest some $$ and time into building a high quality (although smaller still) server to conduct my research.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve been struggling to find good detailed resources/communities for this. Most people seem to be content with the cloud, or their university/company handles this stuff for them. I anticipate that just googling to decide my setup, I&amp;#39;m gonna miss some crucial insider knowledge.&lt;/p&gt;\\n\\n&lt;p&gt;I was hoping someone could offer some tips, or even better point me to a community thats extremely passionate about this side of AI dev? I live in Austin, if there&amp;#39;s any in person communities there, even better!&lt;/p&gt;\\n\\n&lt;p&gt;Ideas I&amp;#39;ve been thinking for initial setup- probably just 2 or 3 4080s to start- I hear about NVLink, but don&amp;#39;t think that&amp;#39;s gonna be an option as someone who&amp;#39;s not well connected- a case (or rack?) and motherboard that can handle a few more (maybe 4-10 GPU capacity)- make sure that other specs (cooling, CPU, PSU, etc.) are appropriate and don&amp;#39;t bottleneck the GPUs- open case? closed case?? idk- would need to be able to ssh in from anywhere in austin, ideally anywhere in the US connection wouldn&amp;#39;t have too bad of latancy- my intention for the setup is to be what you should expect from an extremely new/lean/poor but ambitious and very smart/strategic startup, where people look back and say &amp;quot;wow, that was a well researched and smart setup&amp;quot; LOL&lt;/p&gt;\\n\\n&lt;p&gt;Any advice, any connects, all appreciated. Thanks so much in advance! &amp;lt;3 :-)  &lt;/p&gt;\\n\\n&lt;p&gt;EDIT: Thank you everyone soo so much! Seriously a lot of great resources here, very grateful! Will likely be following a server grade setup as &lt;a href=\"/u/nero10578\"&gt;u/nero10578&lt;/a&gt; mentioned, and still have to dig deeper into a lot of the other resources mentioned as I get into the details of the setup.  &lt;/p&gt;\\n\\n&lt;p&gt;p.s. sorry I posted and ghosted lol, have been hanging with family all week!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18rb7lo', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'margaritasAndBowling', 'discussion_type': None, 'num_comments': 16, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18rb7lo/r_p_selfhosted_gpu_setup_for_ai_research/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18rb7lo/r_p_selfhosted_gpu_setup_for_ai_research/', 'subreddit_subscribers': 2846730, 'created_utc': 1703606395.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"Hello everyone,\\n\\nI'm embarking on a project to create a chatbot for my school's handbook, aiming to make it a resource for students to easily access information. As someone relatively new to AI, I'm seeking guidance on implementing this.\\n\\nMy current plan is to use OpenAI as the primary language learning model, focusing on affordability. I am considering integrating RAG (Retrieval-Augmented Generation) and LangChain for enhanced functionality. However, I'm quite perplexed about choosing an appropriate vector database, as many options appear costly. The goal is to keep this system live and accessible for student usage without breaking the bank.\\n\\nI'm also looking into open-source embedding models to pair with the vector database. Pinecone has caught my attention, but its pricing seems steep for our budget.\\n\\nDoes anyone have recommendations or tips on affordable yet effective tools and strategies for this project? Any insights on vector databases suitable for educational use, or ways to optimize cost without compromising quality, would be greatly appreciated.\\n\\nThank you in advance for your help!\\n\\n(I typed out my problem and had gpt4 fix up the format and wording dont bash me)\", 'author_fullname': 't2_k0ls7hpb', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[P] Seeking Advice for Building a School Handbook Chatbot Using OpenAI and Vector Databases', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18rndcp', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703638319.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m embarking on a project to create a chatbot for my school&amp;#39;s handbook, aiming to make it a resource for students to easily access information. As someone relatively new to AI, I&amp;#39;m seeking guidance on implementing this.&lt;/p&gt;\\n\\n&lt;p&gt;My current plan is to use OpenAI as the primary language learning model, focusing on affordability. I am considering integrating RAG (Retrieval-Augmented Generation) and LangChain for enhanced functionality. However, I&amp;#39;m quite perplexed about choosing an appropriate vector database, as many options appear costly. The goal is to keep this system live and accessible for student usage without breaking the bank.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m also looking into open-source embedding models to pair with the vector database. Pinecone has caught my attention, but its pricing seems steep for our budget.&lt;/p&gt;\\n\\n&lt;p&gt;Does anyone have recommendations or tips on affordable yet effective tools and strategies for this project? Any insights on vector databases suitable for educational use, or ways to optimize cost without compromising quality, would be greatly appreciated.&lt;/p&gt;\\n\\n&lt;p&gt;Thank you in advance for your help!&lt;/p&gt;\\n\\n&lt;p&gt;(I typed out my problem and had gpt4 fix up the format and wording dont bash me)&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18rndcp', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Notchampa', 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18rndcp/p_seeking_advice_for_building_a_school_handbook/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18rndcp/p_seeking_advice_for_building_a_school_handbook/', 'subreddit_subscribers': 2846730, 'created_utc': 1703638319.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Hello folks! I come from a software/data engineering background and would like to transition into the field of machine learning. In software development, the most common problem set for preparing interviews and having a grasp on basic algorithms and data structures is [the LeetCode Blind 75](https://leetcode.com/discuss/general-discussion/460599/blind-75-leetcode-questions). What would be a similar alternative in machine learning? I came across [a post mentioning Kaggle as an alternative for LeetCode in ML](https://www.reddit.com/r/MachineLearning/comments/9ulsqe/discussion_what_the_equivalent_of_leetcode_for/),  but what is the likewise ML equivalent of the Blind 75?\\n\\nThank you in advance!', 'author_fullname': 't2_8pivenr3', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[Discussion] An Alternative to LeetCode Blind 75 for Machine Learning Scientists/Engineers', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18rik1n', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703625538.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks! I come from a software/data engineering background and would like to transition into the field of machine learning. In software development, the most common problem set for preparing interviews and having a grasp on basic algorithms and data structures is &lt;a href=\"https://leetcode.com/discuss/general-discussion/460599/blind-75-leetcode-questions\"&gt;the LeetCode Blind 75&lt;/a&gt;. What would be a similar alternative in machine learning? I came across &lt;a href=\"https://www.reddit.com/r/MachineLearning/comments/9ulsqe/discussion_what_the_equivalent_of_leetcode_for/\"&gt;a post mentioning Kaggle as an alternative for LeetCode in ML&lt;/a&gt;,  but what is the likewise ML equivalent of the Blind 75?&lt;/p&gt;\\n\\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18rik1n', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Choice_Log_6043', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18rik1n/discussion_an_alternative_to_leetcode_blind_75/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18rik1n/discussion_an_alternative_to_leetcode_blind_75/', 'subreddit_subscribers': 2846730, 'created_utc': 1703625538.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'in the paper  \"Adding Conditional Control to Text-to-Image Diffusion Models\" (2302.05543) they add  2 zero convolution layers. the paper emphasise that in the first forward pass the output is the same (since the layer is all zero) and after the first backpropagation, the layer is not all zero anymore - this is ok, just math.\\n\\nhowever it does not explain why was is added? or what does it do? how came they initialize it with zero (when all other papers use different methods to initialize the weights)  \\nwhat would happen if those two Z layers would be left out? could we not train controlnet without them?\\n\\ndo you have an explanation? or a link to further info?', 'author_fullname': 't2_msbb5fih6', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] what do the two zero convolution layers in controlnet do?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18rdkx0', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.65, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703612623.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;in the paper  &amp;quot;Adding Conditional Control to Text-to-Image Diffusion Models&amp;quot; (2302.05543) they add  2 zero convolution layers. the paper emphasise that in the first forward pass the output is the same (since the layer is all zero) and after the first backpropagation, the layer is not all zero anymore - this is ok, just math.&lt;/p&gt;\\n\\n&lt;p&gt;however it does not explain why was is added? or what does it do? how came they initialize it with zero (when all other papers use different methods to initialize the weights)&lt;br/&gt;\\nwhat would happen if those two Z layers would be left out? could we not train controlnet without them?&lt;/p&gt;\\n\\n&lt;p&gt;do you have an explanation? or a link to further info?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18rdkx0', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'FineInstruction1397', 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18rdkx0/d_what_do_the_two_zero_convolution_layers_in/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18rdkx0/d_what_do_the_two_zero_convolution_layers_in/', 'subreddit_subscribers': 2846730, 'created_utc': 1703612623.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'We often see diagrams/figures included in research papers to illustrate the overall workflow. I\\'m curious as to what everyone is using. Personally, I use [draw.io](https://draw.io) and it is usually not \"beautiful\" - so maybe a better alternative?', 'author_fullname': 't2_6yswqna4', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] Which software do you guys use for illustrating research frameworks/ideas ?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18qzdnj', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.97, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 57, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 57, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703563941.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We often see diagrams/figures included in research papers to illustrate the overall workflow. I&amp;#39;m curious as to what everyone is using. Personally, I use &lt;a href=\"https://draw.io\"&gt;draw.io&lt;/a&gt; and it is usually not &amp;quot;beautiful&amp;quot; - so maybe a better alternative?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18qzdnj', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'KarmaCut132', 'discussion_type': None, 'num_comments': 49, 'send_replies': False, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18qzdnj/d_which_software_do_you_guys_use_for_illustrating/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18qzdnj/d_which_software_do_you_guys_use_for_illustrating/', 'subreddit_subscribers': 2846730, 'created_utc': 1703563941.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': '**Paper**: [https://openreview.net/forum?id=psXVkKO9No](https://openreview.net/forum?id=psXVkKO9No)\\n\\n**Abstract**:\\n\\n&gt;Reinforcement Learning (RL) algorithms typically utilize learning  and/or  planning techniques to derive effective policies. The  integration of  both approaches has proven to be highly successful in  addressing complex  sequential decision-making challenges, as evidenced  by algorithms such  as AlphaZero and MuZero, which consolidate the  planning process into a  parametric search-policy. AIXI, the most potent  theoretical universal  agent, leverages planning through comprehensive  search as its primary  means to find an optimal policy. Here we define  an alternative universal  agent, which we call **Self-AIXI**,  that on the contrary to AIXI, maximally  exploits learning to obtain  good policies. It does so by  self-predicting its own stream of action  data, which is generated,  similarly to other TD(0) agents, by taking an  action maximization step  over the current on-policy (universal  mixture-policy) Q-value estimates.  We prove that Self-AIXI converges to  AIXI, and inherits a series of  properties like maximal Legg-Hutter  intelligence and the self-optimizing  property.', 'author_fullname': 't2_mveclxvsc', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[R] \"Self-Predictive Universal AI\" (Self-AIXI)', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18r88hb', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.71, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 7, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703597634.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Paper&lt;/strong&gt;: &lt;a href=\"https://openreview.net/forum?id=psXVkKO9No\"&gt;https://openreview.net/forum?id=psXVkKO9No&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Reinforcement Learning (RL) algorithms typically utilize learning  and/or  planning techniques to derive effective policies. The  integration of  both approaches has proven to be highly successful in  addressing complex  sequential decision-making challenges, as evidenced  by algorithms such  as AlphaZero and MuZero, which consolidate the  planning process into a  parametric search-policy. AIXI, the most potent  theoretical universal  agent, leverages planning through comprehensive  search as its primary  means to find an optimal policy. Here we define  an alternative universal  agent, which we call &lt;strong&gt;Self-AIXI&lt;/strong&gt;,  that on the contrary to AIXI, maximally  exploits learning to obtain  good policies. It does so by  self-predicting its own stream of action  data, which is generated,  similarly to other TD(0) agents, by taking an  action maximization step  over the current on-policy (universal  mixture-policy) Q-value estimates.  We prove that Self-AIXI converges to  AIXI, and inherits a series of  properties like maximal Legg-Hutter  intelligence and the self-optimizing  property.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/uqSXAZWnIeNKGNM9S7DGpGLOnzm_mxUMvr6Y0yks4jY.jpg?auto=webp&amp;s=71ad6a8a2e6e5fac511957278effb619d3b30998', 'width': 512, 'height': 512}, 'resolutions': [{'url': 'https://external-preview.redd.it/uqSXAZWnIeNKGNM9S7DGpGLOnzm_mxUMvr6Y0yks4jY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c811689cb2c2b238253833845bad24e74bdb5d8', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/uqSXAZWnIeNKGNM9S7DGpGLOnzm_mxUMvr6Y0yks4jY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=79517bf9d18cf488552e43744ad2c342af22479f', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/uqSXAZWnIeNKGNM9S7DGpGLOnzm_mxUMvr6Y0yks4jY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d4b56b82708f12907eed5cb9688415ff2947f8a5', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'A2cFENtZsGUk4TdgVLLL25zXBQBwmcPSG87hZLopV-w'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18r88hb', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'APaperADay', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18r88hb/r_selfpredictive_universal_ai_selfaixi/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18r88hb/r_selfpredictive_universal_ai_selfaixi/', 'subreddit_subscribers': 2846730, 'created_utc': 1703597634.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"I'm currently working on a project focused on human fall detection using channel state information (CSI). As part of this, I'm exploring various feature extraction methods. However, I'm uncertain about the optimal features to extract from the frequency domain.\\n\\nIn its original format, my data in the time domain is structured as a 2D array. Each row corresponds to a millisecond, and each column represents a subcarrier. The value at each location indicates the signal's amplitude.\\n\\nI converted the data to the frequency domain with an FFT. I would appreciate any insights or suggestions on which features to extract from the data in the frequency domain.\", 'author_fullname': 't2_6qiaybig', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[P] Feature Extraction for Channel State Information in the Frequency Domain for Human Activity Recognition', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18rdu04', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703613265.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working on a project focused on human fall detection using channel state information (CSI). As part of this, I&amp;#39;m exploring various feature extraction methods. However, I&amp;#39;m uncertain about the optimal features to extract from the frequency domain.&lt;/p&gt;\\n\\n&lt;p&gt;In its original format, my data in the time domain is structured as a 2D array. Each row corresponds to a millisecond, and each column represents a subcarrier. The value at each location indicates the signal&amp;#39;s amplitude.&lt;/p&gt;\\n\\n&lt;p&gt;I converted the data to the frequency domain with an FFT. I would appreciate any insights or suggestions on which features to extract from the data in the frequency domain.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18rdu04', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Snoo386', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18rdu04/p_feature_extraction_for_channel_state/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18rdu04/p_feature_extraction_for_channel_state/', 'subreddit_subscribers': 2846730, 'created_utc': 1703613265.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Suppose that I want a model to predict Y based on X. I know that Y = f(X) for some already known f is a good approximation, but not a perfect one. Thus, I wish to have a neural networks g, h such that Y = h(f(X), g(X)) is a better approximation. However, if I simply add a big network g and h, then I will seriously over-parameterise, since f(X) is already very good.\\n\\nIs there a technique (e.g. a nicely cooked up loss function) to discourage putting too much weight into the g(X) part? It would be really helpful if I could find some research on this.', 'author_fullname': 't2_o0tidhzqj', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] ML techniques of encouraging small weight on certain parts of input?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18rkush', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.6, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703631570.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Suppose that I want a model to predict Y based on X. I know that Y = f(X) for some already known f is a good approximation, but not a perfect one. Thus, I wish to have a neural networks g, h such that Y = h(f(X), g(X)) is a better approximation. However, if I simply add a big network g and h, then I will seriously over-parameterise, since f(X) is already very good.&lt;/p&gt;\\n\\n&lt;p&gt;Is there a technique (e.g. a nicely cooked up loss function) to discourage putting too much weight into the g(X) part? It would be really helpful if I could find some research on this.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18rkush', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'speedy-spade', 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18rkush/d_ml_techniques_of_encouraging_small_weight_on/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18rkush/d_ml_techniques_of_encouraging_small_weight_on/', 'subreddit_subscribers': 2846730, 'created_utc': 1703631570.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': '**Project**: [https://github.com/aymenfurter/microagents](https://github.com/aymenfurter/microagents)\\n\\n**Description**:\\n\\n&gt;This experiment explores self-evolving agents that automatically  generate and improve themselves. No specific agent design or prompting  is required from the user. Simply pose a question, and the system  initiates and evolves agents tailored to provide answers. The process  starts with a user query, activating a basic \"bootstrap\" agent, which  doesn\\'t execute Python code but plans and delegates to specialized  agents capable of running Python for broader functions. An Agent Manager  oversees them, selecting or creating agents via vector similarity for  specific tasks. Agents have evolving system prompts that improve through  learning. For coding tasks, agents include Python in prompts, refining  their approach through an \"evolution step\" if unsuccessful. Upon  completing a task, an agent\\'s status updates, and the bootstrap agent  evaluates the result, engaging other agents for further steps in larger  processes.', 'author_fullname': 't2_mveclxvsc', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[P] microagents: Modular Agents Capable of Self-Editing Their Prompts and Python code', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18r6wqx', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.82, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 7, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703592941.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Project&lt;/strong&gt;: &lt;a href=\"https://github.com/aymenfurter/microagents\"&gt;https://github.com/aymenfurter/microagents&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;This experiment explores self-evolving agents that automatically  generate and improve themselves. No specific agent design or prompting  is required from the user. Simply pose a question, and the system  initiates and evolves agents tailored to provide answers. The process  starts with a user query, activating a basic &amp;quot;bootstrap&amp;quot; agent, which  doesn&amp;#39;t execute Python code but plans and delegates to specialized  agents capable of running Python for broader functions. An Agent Manager  oversees them, selecting or creating agents via vector similarity for  specific tasks. Agents have evolving system prompts that improve through  learning. For coding tasks, agents include Python in prompts, refining  their approach through an &amp;quot;evolution step&amp;quot; if unsuccessful. Upon  completing a task, an agent&amp;#39;s status updates, and the bootstrap agent  evaluates the result, engaging other agents for further steps in larger  processes.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/EH9sTF-dj7yqciWp18DWG9VdrIu0AtS7Cg3OJcybLyc.jpg?auto=webp&amp;s=8b66b1e0a606a135aa1d5c95bb6d7aeba03bc193', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/EH9sTF-dj7yqciWp18DWG9VdrIu0AtS7Cg3OJcybLyc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=32963822cbf63f32b421cd1af4751f6a17b243b0', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/EH9sTF-dj7yqciWp18DWG9VdrIu0AtS7Cg3OJcybLyc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7f812577811ecbaddcb3e19d5c9e8b19f2302862', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/EH9sTF-dj7yqciWp18DWG9VdrIu0AtS7Cg3OJcybLyc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=54f51e305c9795182ebc021161bcc2e35e8903df', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/EH9sTF-dj7yqciWp18DWG9VdrIu0AtS7Cg3OJcybLyc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d58898433ed18ed43a082530fd40942eadd4c9e4', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/EH9sTF-dj7yqciWp18DWG9VdrIu0AtS7Cg3OJcybLyc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=85d315db82be88756d789b1bc4c58ca7b96e8efd', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/EH9sTF-dj7yqciWp18DWG9VdrIu0AtS7Cg3OJcybLyc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fd86808666fdeb05159fc9ca06471c459bd8e661', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'A6dEO0qT0lGPOSfu1Xj84p5etU1nGS5F2KnOkUHySNg'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18r6wqx', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'APaperADay', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18r6wqx/p_microagents_modular_agents_capable_of/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18r6wqx/p_microagents_modular_agents_capable_of/', 'subreddit_subscribers': 2846730, 'created_utc': 1703592941.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}], 'before': None}}\n"
     ]
    }
   ],
   "source": [
    "print(json_data)\n",
    "with open(\"data.json\", \"w\") as outfile:\n",
    "    json.dump(json_data,outfile,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your company wants you to get relevant data from that endpoint - ensure that data is easily useable.\n",
    "# Make a CSV file with all relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/t4nb46zd6m941nngrr_c4dt00000gn/T/ipykernel_22532/4226301316.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_core[\"created\"] = pd.to_datetime(df_core[\"created\"], unit ='s')\n"
     ]
    }
   ],
   "source": [
    "with open('data.json', 'r') as json_file:   \n",
    "    data_dict = json.load(json_file)\n",
    "#one way to get data from json file\n",
    "#child_list = [child.get('data', {}) for child in data_dict.get('data',{}).get('children',[])]\n",
    "#print(child_list)\n",
    "\n",
    "#another easy way to get data from json file\n",
    "df = json_data[\"data\"][\"children\"]\n",
    "df = [child[\"data\"] for child in df]\n",
    "df = pd.DataFrame(df)\n",
    "#print(df.head())\n",
    "\n",
    "#Feature selection\n",
    "features = [\"title\", \"num_comments\", \"ups\", \"upvote_ratio\", \"created\"]\n",
    "df_core = df[features]\n",
    "df_core[\"created\"] = pd.to_datetime(df_core[\"created\"], unit ='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/t4nb46zd6m941nngrr_c4dt00000gn/T/ipykernel_22532/3914528158.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_core[\"title\"] = df_core[\"title\"].str.strip()\n"
     ]
    }
   ],
   "source": [
    "df_core[\"title\"] = df_core[\"title\"].str.strip()\n",
    "df_core.head()\n",
    "df_core.to_csv(\"subreddit_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
